{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the paths\n",
    "# input_file_path = \"./antarctic_index.gpkg\"\n",
    "# map_path = \"/Users/nathanbekele/Downloads/Quantarctica3/Miscellaneous/SimpleBasemap/ADD_DerivedLowresBasemap.shp\"\n",
    "\n",
    "# # Read the GeoPackage file\n",
    "# gdf = gpd.read_file(input_file_path)\n",
    "\n",
    "# # Print the first few rows of the GeoDataFrame\n",
    "# print(\"First few rows of the GeoDataFrame:\")\n",
    "# print(gdf.head())\n",
    "\n",
    "# # Display unique institutions to check if 'AWI' is present\n",
    "# print(\"\\nUnique institutions in the dataset:\")\n",
    "# print(gdf['institution'].unique())\n",
    "\n",
    "# # Filter the GeoDataFrame for the institution 'AWI'\n",
    "# filtered_gdf = gdf[gdf['institution'] == 'AWI']\n",
    "\n",
    "# # Print the unique institutions in the filtered GeoDataFrame\n",
    "# print(\"\\nUnique institutions in the filtered GeoDataFrame:\")\n",
    "# print(filtered_gdf['institution'].unique())\n",
    "\n",
    "# # Check if the filtered GeoDataFrame is empty\n",
    "# print(f\"\\nFiltered GeoDataFrame for AWI is empty: {filtered_gdf.empty}\")\n",
    "\n",
    "# # Print the first few rows of the filtered GeoDataFrame to confirm filtering\n",
    "# print(\"\\nFirst few rows of the filtered GeoDataFrame:\")\n",
    "# print(filtered_gdf.head())\n",
    "\n",
    "# # Print the CRS of the filtered GeoDataFrame\n",
    "# print(\"\\nCRS of the filtered GeoDataFrame before transformation:\")\n",
    "# print(filtered_gdf.crs)\n",
    "\n",
    "# # Read the basemap shapefile\n",
    "# basemap = gpd.read_file(map_path)\n",
    "\n",
    "# # Print the CRS of the basemap\n",
    "# print(\"\\nCRS of the basemap:\")\n",
    "# print(basemap.crs)\n",
    "\n",
    "# # Ensure the CRS matches between the basemap and the GeoDataFrame\n",
    "# if not filtered_gdf.empty:\n",
    "#     filtered_gdf = filtered_gdf.to_crs(basemap.crs)\n",
    "\n",
    "# # Print the CRS of the filtered GeoDataFrame after transformation\n",
    "# print(\"\\nCRS of the filtered GeoDataFrame after transformation:\")\n",
    "# print(filtered_gdf.crs)\n",
    "\n",
    "# # Function to plot data on the basemap\n",
    "# def plot_data_on_basemap(basemap, gdf):\n",
    "#     fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "#     # Set background color to light blue\n",
    "#     fig.patch.set_facecolor('lightblue')\n",
    "#     ax.set_facecolor('lightblue')\n",
    "    \n",
    "#     # Plot basemap with Antarctica as white\n",
    "#     basemap.plot(ax=ax, color='white', edgecolor='black')\n",
    "    \n",
    "#     # Plot the data\n",
    "#     if not gdf.empty:\n",
    "#         print(\"\\nPlotting data:\")\n",
    "#         print(gdf)\n",
    "#         gdf.plot(ax=ax, color='red', linewidth=2)\n",
    "#     else:\n",
    "#         print(\"GeoDataFrame is empty, nothing to plot.\")\n",
    "\n",
    "#     # Set limits to zoom in on Antarctica\n",
    "#     ax.set_xlim(-3e6, 3e6)\n",
    "#     ax.set_ylim(-3e6, 3e6)\n",
    "    \n",
    "#     # Remove axis for cleaner look\n",
    "#     ax.set_axis_off()\n",
    "    \n",
    "#     plt.title('Antarctica Basemap with AWI Data Overlay')\n",
    "#     plt.show()\n",
    "\n",
    "# # Plot the data\n",
    "# plot_data_on_basemap(basemap, filtered_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basemap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(basemap\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'basemap' is not defined"
     ]
    }
   ],
   "source": [
    "print(basemap.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "# Define the paths\n",
    "input_file_path = \"./antarctic_index.gpkg\"\n",
    "map_path = \"/Users/nathanbekele/Downloads/Quantarctica3/Miscellaneous/SimpleBasemap/ADD_DerivedLowresBasemap.shp\"\n",
    "output_folder = \"./data3\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all layers in the GeoPackage\n",
    "try:\n",
    "    layers = gpd.io.file.fiona.listlayers(input_file_path)\n",
    "    if layers is None:\n",
    "        raise ValueError(\"No layers found in the GeoPackage.\")\n",
    "    print(\"Layers in the GeoPackage:\")\n",
    "    print(layers)\n",
    "except Exception as e:\n",
    "    print(f\"Error listing layers in the GeoPackage: {e}\")\n",
    "    layers = []\n",
    "\n",
    "if not layers:\n",
    "    print(\"No layers found or error in listing layers. Exiting.\")\n",
    "else:\n",
    "    # Create a dictionary to map institutions to layers\n",
    "    institution_layers = {}\n",
    "\n",
    "    # Populate the dictionary\n",
    "    for layer in layers:\n",
    "        try:\n",
    "            gdf_head = gpd.read_file(input_file_path, layer=layer, rows=10)  # Read first 10 rows\n",
    "            gdf_tail = gpd.read_file(input_file_path, layer=layer, skiprows=lambda x: x < (gdf_head.shape[0] - 10))  # Read last 10 rows\n",
    "            if 'institution' in gdf_head.columns:\n",
    "                institutions = set(gdf_head['institution'].unique()).union(set(gdf_tail['institution'].unique()))\n",
    "                for institution in institutions:\n",
    "                    if institution is not None:\n",
    "                        if institution not in institution_layers:\n",
    "                            institution_layers[institution] = []\n",
    "                        institution_layers[institution].append(layer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading layer {layer}: {e}\")\n",
    "\n",
    "    print(\"Institution layers mapping:\")\n",
    "    print(institution_layers)\n",
    "\n",
    "    # Read the basemap shapefile\n",
    "    basemap = gpd.read_file(map_path)\n",
    "\n",
    "    # Function to plot data on the basemap with color-coding based on availability\n",
    "    def plot_data_on_basemap(basemap, gdf, institution, output_folder):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "        # Set background color to white\n",
    "        fig.patch.set_facecolor('white')\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        # Plot basemap with Antarctica as white\n",
    "        basemap.plot(ax=ax, color='white', edgecolor='black')\n",
    "        \n",
    "        # Define colors based on availability\n",
    "        colors = {'u': 'darkblue', 's': 'red', '': 'darkgrey'}\n",
    "        labels = {'u': 'Available', 's': 'Unavailable', '': 'Dark Grey'}\n",
    "        \n",
    "        # Plot the data for the institution\n",
    "        if not gdf.empty:\n",
    "            for availability in gdf['availability'].unique():\n",
    "                subset = gdf[gdf['availability'] == availability]\n",
    "                color = colors.get(availability, 'darkgrey')\n",
    "                subset.plot(ax=ax, color=color, markersize=0.2, linewidth=0.2, label=f\"{labels.get(availability, 'Dark Grey')}\")\n",
    "        else:\n",
    "            print(\"GeoDataFrame is empty, nothing to plot.\")\n",
    "\n",
    "        # Set limits to zoom in on Antarctica\n",
    "        ax.set_xlim(-3e6, 3e6)\n",
    "        ax.set_ylim(-3e6, 3e6)\n",
    "        \n",
    "        # Add axis labels for coordinates\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        \n",
    "        # Add a scalebar\n",
    "        scalebar = ScaleBar(1, location='lower right')\n",
    "        ax.add_artist(scalebar)\n",
    "        \n",
    "        plt.title(f'Antarctica Basemap with {institution} Data Overlay')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save the plot to the data folder\n",
    "        output_path = os.path.join(output_folder, f'Antarctica_coverage_{institution}.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved map for {institution} to {output_path}\")\n",
    "\n",
    "    # Iterate through each institution and create maps\n",
    "    all_data = []\n",
    "    for institution, layers in institution_layers.items():\n",
    "        institution_data = []\n",
    "\n",
    "        print(f\"\\nProcessing institution: {institution}\")\n",
    "        \n",
    "        for layer in layers:\n",
    "            print(f\"Checking layer: {layer}\")\n",
    "            try:\n",
    "                gdf = gpd.read_file(input_file_path, layer=layer)  # Read the full layer\n",
    "                \n",
    "                if 'institution' in gdf.columns and institution in gdf['institution'].unique():\n",
    "                    print(f\"Layer '{layer}' contains '{institution}'.\")\n",
    "                    institution_data.append(gdf[gdf['institution'] == institution])\n",
    "                else:\n",
    "                    print(f\"Layer '{layer}' does not contain '{institution}' or does not have 'institution' column.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing layer {layer}: {e}\")\n",
    "\n",
    "        # Combine all dataframes for the institution\n",
    "        if institution_data:\n",
    "            institution_gdf = gpd.GeoDataFrame(pd.concat(institution_data, ignore_index=True))\n",
    "            all_data.append(institution_gdf)\n",
    "        else:\n",
    "            institution_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "        # Ensure the CRS matches between the basemap and the GeoDataFrame\n",
    "        if not institution_gdf.empty:\n",
    "            institution_gdf = institution_gdf.to_crs(basemap.crs)\n",
    "\n",
    "        # Plot and save the aggregated data for the institution\n",
    "        plot_data_on_basemap(basemap, institution_gdf, institution, output_folder)\n",
    "\n",
    "    # Generate an overview map\n",
    "    if all_data:\n",
    "        all_data_gdf = gpd.GeoDataFrame(pd.concat(all_data, ignore_index=True))\n",
    "        plot_data_on_basemap(basemap, all_data_gdf, 'Overview', output_folder)\n",
    "\n",
    "    print(\"All maps have been created and saved to the data3 folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
